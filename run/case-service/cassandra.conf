##################################################################################################
##                                                                                              ##
## Default configurations to use                                                                ##
##   - Cassandra for storing events                                                             ##
##   - PostgreSQL for building up projections database for case queries                         ##
##                                                                                              ##
##  Some of the settings can be passed as environment variables                                 ##
##                                                                                              ##
##################################################################################################
akka {
  loglevel = INFO
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logger-startup-timeout = 10s

  actor {
    serialize-messages = on

    serializers {
      cafienne_serializer = "org.cafienne.infrastructure.serialization.CafienneSerializer"
    }

    serialization-bindings {
      "org.cafienne.infrastructure.serialization.CafienneSerializable" = cafienne_serializer
    }
  }

  persistence {
    journal {
      plugin = "cassandra-journal"
      auto-start-journals = ["cassandra-journal"]
    }
    snapshot-store {
      plugin = "cassandra-snapshot-store"
    }
  }
}

cafienne {
  # Engine wide platform settings
  platform {
    # Platform has owners that are allowed to create/disable/enable tenants
    #  This property specifies the set of user-id's that are owners
    #  This array may not be empty.
    owners = ["admin"]
    owners = ${?CAFIENNE_PLATFORM_OWNERS}
    # Default tenant will be used when a user does not provide the tenant as a parameter to
    #  the API call (e.g. in StartCase). When the user is member of only one tenant,
    #  then that tenant will be submitted along with the StartCase command.
    #  If the user belongs to multiple tenants, then this default-tenant option will be passed.
    default-tenant = "world"
    default-tenant = ${?CAFIENNE_PLATFORM_DEFAULT_TENANT}
    # bootstrap-tenants holds a reference to zero or more json (or yaml) files that have default tenant information.
    #  Each file is should contain information for one tenant (tenant name, users and owners).
    #  During launch of the case engine, the files will be scanned and a CreateTenant command is sent
    #  into the system, thereby setting up one or more default tenants.
    # If the bootstrap-tenants property is not filled and the default-tenant has a value, the system will search for
    #  a file that holds the default tenant name plus either a .conf, .json, .yml or .yaml extension.
    #  E.g. in case default-tenant = 'world', the system would search for existence in the following order:
    #  - 'world.conf'
    #  - 'world.json'
    #  - 'world.yml'
    #  - 'world.yaml'
    # If none of these files are found, the bootstrap attempt will be skipped.
    bootstrap-tenants = ["world.conf"]
  }

  engine {
    # Properties for sending tasks of type Mail
    mail-service {
      # Here you can fill any regular javax.mail properties
      #  All properties mentioned here are passed into the connection with the mail server
      mail.host = mailcatcher
      mail.smtp.port = 1025
      # Optional username/pwd to be used to connect to the mail server
      authentication {
        user = ""
        password = ""
      }
    }
  }

  api {
    bindhost = "localhost"
    bindport = 2027

    security {
      # configuration settings for OpenID Connect
      oidc {
        ##################################################################################
        ##  Below settings can be used to configure to the default DEX OIDC service     ##
        ##   that ships with the docker images in the cafienne repository named         ##
        ##   getting-started.                                                           ##
        ##################################################################################
        connect-url = "http://localhost:5556/dex/.well-known/openid-configuration"
        token-url = "http://localhost:5556/dex/token"
        key-url = "http://localhost:5556/dex/keys"
        authorization-url = "http://localhost:5556/dex/auth"
        issuer = "http://localhost:5556/dex"

        ##################################################################################
        ##  Below settings can be used to configure to the untrustworthy token service  ##
        ##   Only use this to run the Cafienne Testscript Framework for test purposes.  ##
        ##   Never use this in production systems.                                      ##
        ##################################################################################
        connect-url = "http://localhost:2377/.well-known/openid-configuration"
        token-url = "http://localhost:2377/token"
        key-url = "http://localhost:2377/keys"
        authorization-url = "http://localhost:2377/auth"
        issuer = "Cafienne Test Framework"

        ##################################################################################
        ##  Potentially override with environment variables, e.g. to apply the DEX set  ##
        ##################################################################################
        connect-url = ${?CAFIENNE_OIDC_CONNECT_URL}
        token-url = ${?CAFIENNE_OIDC_TOKEN_URL}
        key-url = ${?CAFIENNE_OIDC_KEY_URL}
        authorization-url = ${?CAFIENNE_OIDC_AUTHORIZATION_URL}
        issuer = ${?CAFIENNE_OIDC_ISSUER}
      }

      # The subject of a valid JWT token is used to query the corresponging registered platform user from the database.
      # These identities can be cached to avoid repeated queries and thereby improve throughput times.
      # The size of the cache can be set here, it defaults to 1000
      # The cache is disabled if size is 0 or a negative number.
      identity.cache.size = 1000

      ###################################################################################################
      ##                                                                                               ##
      ## Fill this setting to true to allow developers to access engine events without authentication  ##
      ##                                                                                               ##
      ##   WARNING - Enabling opens up the full engine in read-only mode for anyone to access          ##
      ##                                                                                               ##
      ###################################################################################################
      debug.events.open = true
      debug.events.open = ${?CAFIENNE_DEBUG_EVENTS}
    }
  }

  # The case engine supports various ways to list, load and deploy case definitions.
  # The below settings can be used to configure various options; default settings use
  # a file based definition provider.
  # An alternative is to use the StartCaseDefinitionProvider, in which
  # case definitions must be passed along with the StartCase REST API itself.
  #
  # The case engine reads definitions as XML files from disk and/or the classpath.
  # The files are cached in-memory, based on their lastModified timestamp
  # (i.e., if you change a file on disk, the engine will reload it into the cache).
  # By default, the engine will read from the configured location. If the definitions file cannot be found
  # in this location, the engine will try to load it as a resource from the classpath, hence enabling to ship
  # fixed definitions in a jar file.
  definitions {
    # Default provider is based on reading/writing from the local file system
    provider = "org.cafienne.cmmn.repository.file.FileBasedDefinitionProvider"
    location = "./definitions"
    location =  ${?CAFIENNE_CMMN_DEFINITIONS_PATH}
    cache {
      size = 100
    }

    # Use the below provider to start cases while passing the definition along the StartCase call
    #  Note that the StartCaseDefinitionProvider also makes use of the same cache settings
    # provider = "org.cafienne.cmmn.repository.StartCaseDefinitionProvider"
  }

  actor {
    # the seconds of idle time after which a case actor is removed from akka memory
    # if the case has not received new commands after the specified number of seconds,
    # the case engine will ask akka to remove the case from memory to avoid memory leaks.
    idle-period = 600

    # If debug is true, then all StartCase commands by default will run in debug mode,
    #  unless specified otherwise in the command
    debug = true
  }

  # This setting tells cafienne which journal to use for reading events.
  #  If omitted, cafienne will try to guess the read journal, based on the akka settings
  read-journal = "cassandra-query-journal"

  query-db {
    profile = "slick.jdbc.PostgresProfile$"
    profile = ${?QUERY_DB_PROFILE}
    db {
      driver = "org.postgresql.Driver"
      driver =  ${?QUERY_DB_DRIVER}
      ###################################################################
      ##                                                               ##
      ##  Database schema 'cafienne-query' must be created manually    ##
      ##                                                               ##
      ###################################################################
      url = "jdbc:postgresql://localhost:5432/cafienne-cassandra-query?reWriteBatchedInserts=true"
      url =  ${?QUERY_DB_URL}

      ###################################################################
      ##                                                               ##
      ##  MAKE SURE TO FILL USER AND PASSWORD FOR CONNECTION           ##
      ##                                                               ##
      ###################################################################
      user = ""
      user =  ${?QUERY_DB_USER}
      password = ""
      password =  ${?QUERY_DB_PASSWORD}
      numThreads = 10
      connectionTimeout = 5000
      validationTimeout = 5000
    }

    # Configuration options handling exceptions that may occur while reading
    #  the event streams that populate the query-db tables
    #  See also https://doc.akka.io/docs/akka/current/stream/stream-error.html#restart-with-backoff
    restart-stream {
        min-back-off = 500ms
        max-back-off = 30s
        random-factor = 0.20
        max-restarts = 20
        max-restarts-within = 5m
    }
  }
}


####################################################################################
##                                                                                ##
##  Below are settings for Akka Event Storage for Cassandra                       ##
##                                                                                ##
####################################################################################
cassandra-journal {
  keyspace-autocreate = true
  tables-autocreate = true

  event-adapters {
    tagging = "org.cafienne.actormodel.tagging.CaseTaggingEventAdapter"
  }

  event-adapter-bindings {
    "org.cafienne.actormodel.event.ModelEvent" = tagging
  }

  events-by-tag {
    query-plugin = cassandra-query-journal
  }
}

cassandra-query-journal {
  # Implementation class of the Cassandra ReadJournalProvider
  class = "akka.persistence.cassandra.query.CassandraReadJournalProvider"

  # First time bucket dramatically improves startup performance if projections starts freshly with NoOffset
  first-time-bucket = "20200101T00:00"

  session-provider = "akka.cassandra.session.DefaultSessionProvider"
  session-name = ""

  # Absolute path to the write journal plugin configuration section
  write-plugin = "cassandra-journal"
  read-profile = "cassandra-journal"

  # NOTE: Setting refresh-interval to less than 2 seconds is not recommended.
  refresh-interval = 100ms
  events-by-tag {
    refresh-interval = 100ms
    eventual-consistency-delay = 100ms
  }
}

cassandra-snapshot-store {

  # FQCN of the cassandra snapshot store plugin
  class = "akka.persistence.cassandra.snapshot.CassandraSnapshotStore"

  # Comma-separated list of contact points in the cluster
  contact-points = [localhost]

  # Port of contact points in the cluster
  port = 9042

  # Name of the keyspace to be created/used by the snapshot store
  keyspace = "akka_snapshot"

  # Parameter indicating whether the snapshot keyspace should be auto created
  keyspace-autocreate = true

  # In case that schema creation failed you can define a number of retries before giving up.
  keyspace-autocreate-retries = 1

  # Number of retries before giving up connecting to the cluster
  connect-retries = 3

  # Delay between connection retries
  connect-retry-delay = 5s

  # Name of the table to be created/used by the snapshot store
  table = "snapshots"

  # Compaction strategy for the snapshot table
  table-compaction-strategy {
    class = "SizeTieredCompactionStrategy"
  }

  # Name of the table to be created/used for journal config
  config-table = "config"

  # Name of the table to be created/used for storing metadata
  metadata-table = "metadata"

  # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
  replication-strategy = "SimpleStrategy"

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  data-center-replication-factors = []

  # Write consistency level
  write-consistency = "ONE"

  # Read consistency level
  read-consistency = "ONE"

  # Maximum number of snapshot metadata to load per recursion (when trying to
  # find a snapshot that matches specified selection criteria). Only increase
  # this value when selection criteria frequently select snapshots that are
  # much older than the most recent snapshot i.e. if there are much more than
  # 10 snapshots between the most recent one and selected one. This setting is
  # only for increasing load efficiency of snapshots.
  max-metadata-result-size = 10

  # Maximum size of result set
  max-result-size = 50001

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "cassandra-snapshot-store.default-dispatcher"

  # Default dispatcher for plugin actor.
  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 8
    }
  }
}