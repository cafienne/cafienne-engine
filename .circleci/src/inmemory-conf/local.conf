# Default application.conf runs the Case Service with
#  Cassandra as storage for events and
#  Postgres as storage for the projections to enable the Case queries and
#  Akka as the runtime system
# All of these can be configured through this conf file.
# In addition many settings can also be passed as environment variables

akka {
  loglevel = INFO
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logger-startup-timeout = 10s

  actor {
    serialize-messages = on

    serializers {
      cafienne_serializer = "org.cafienne.actormodel.serialization.CafienneSerializer"
    }

    serialization-bindings {
      "org.cafienne.actormodel.serialization.CafienneSerializable" = cafienne_serializer
    }
  }

  persistence {
    journal {
      # Using Dennis Vriend in-mem journal
      plugin = "inmemory-journal"
      auto-start-journals = ["inmemory-journal"]
    }

    snapshot-store {
      plugin = "inmemory-snapshot-store"
    }
  }
}

cafienne {
  # Engine wide platform settings
  platform {
    # Platform has owners that are allowed to create/disable/enable tenants
    #  This property specifies the set of user-id's that are owners
    #  This array may not be empty.
    owners = ["admin", "CgVhZG1pbhIFbG9jYWw"]
    owners = ${?CAFIENNE_PLATFORM_OWNERS}
    # Default tenant will be used when a user does not provide the tenant as a parameter to
    #  the API call (e.g. in StartCase). When the user is member of only one tenant,
    #  then that tenant will be submitted along with the StartCase command.
    #  If the user belongs to multiple tenants, then this default-tenant option will be passed.
    default-tenant = "world"
    default-tenant = ${?CAFIENNE_PLATFORM_DEFAULT_TENANT}
    # bootstrap-file holds a reference to a json or yaml file that has default tenant information.
    #  E.g., tenant name, tenant owners, tenant users can be given in this file.
    #  During launch of the case engine, the file will be scanned and a special CreateTenant command is sent
    #  into the system, thereby setting up a default tenant with owners and users.
    #  The bootstrap configuration will search for this file, and try to parse it into a standard akka Config
    #  object.
    # If the bootstrap-file property is not filled, the system will search for a file that holds
    #  the default tenant name plus either a .conf, .json, .yml or .yaml extension.
    #  In case of tenant 'world', the system would search for existence in the following order:
    #  - 'world.conf'
    #  - 'world.json'
    #  - 'world.yml'
    #  - 'world.yaml'
    # If none of these files are found, the bootstrap attempt will be skipped.
    bootstrap-file = "bootstrap/world.tenant.conf"
  }

  engine {
    # Properties for sending tasks of type Mail
    mail-service {
      # Here you can fill any regular javax.mail properties
      #  All properties mentioned here are passed into the connection with the mail server
      mail.host = localhost
      mail.smtp.port = 1025
      # Optional username/pwd to be used to connect to the mail server
      authentication {
        user = ""
        password = ""
      }
    }

    platform-service {
      # Number of threads to push platform updates to cases and tenants
      workers = 10
      # The number of seconds that the PlatformService should wait to persist it's snapshots
      persist-delay = 5
    }
  }

  api {
    bindhost = "0.0.0.0"
    bindport = 2027

    security {
      # configuration settings for OpenID Connect
      oidc {
        ##################################################################################
        ##  Below settings can be used to configure to the untrustworthy token service  ##
        ##   Only use this to run the Cafienne Testscript Framework for test purposes.  ##
        ##   Never use this in production systems.                                      ##
        ##################################################################################
        connect-url = "http://localhost:2377/.well-known/openid-configuration"
        token-url = "http://localhost:2377/token"
        key-url = "http://localhost:2377/keys"
        authorization-url = "http://localhost:2377/auth"
        issuer = "Cafienne Test Framework"
      }

       ###################################################################################################
      ##                                                                                               ##
      ## Fill this setting to true to allow developers to access engine events without authentication  ##
      ##                                                                                               ##
      ##   WARNING - Enabling opens up the full engine in read-only mode for anyone to access          ##
      ##                                                                                               ##
      ###################################################################################################
      debug.events.open = true
      debug.events.open = ${?CAFIENNE_DEBUG_EVENTS}
    }
  }

  # The case engine supports various ways to list, load and deploy case definitions.
  # The below settings can be used to configure various options; default settings use
  # a file based definition provider.
  # An alternative is to use the StartCaseDefinitionProvider, in which
  # case definitions must be passed along with the StartCase REST API itself.
  #
  # The case engine reads definitions as XML files from disk and/or the classpath.
  # The files are cached in-memory, based on their lastModified timestamp
  # (i.e., if you change a file on disk, the engine will reload it into the cache).
  # By default, the engine will read from the configured location. If the definitions file cannot be found
  # in this location, the engine will try to load it as a resource from the classpath, hence enabling to ship
  # fixed definitions in a jar file.
  definitions {
    # Default provider is based on reading/writing from the local file system
    provider = "org.cafienne.cmmn.repository.file.FileBasedDefinitionProvider"
    location = "./definitions"
    location =  ${?CAFIENNE_CMMN_DEFINITIONS_PATH}
    cache {
      size = 100
    }

    # Use the below provider to start cases while passing the definition along the StartCase call
    #  Note that the StartCaseDefinitionProvider also makes use of the same cache settings
    # provider = "org.cafienne.cmmn.repository.StartCaseDefinitionProvider"
  }

  actor {
    # the seconds of idle time after which a case actor is removed from akka memory
    # if the case has not received new commands after the specified number of seconds,
    # the case engine will ask akka to remove the case from memory to avoid memory leaks.
    idle-period = 600

    # If debug is true, then all StartCase commands by default will run in debug mode,
    #  unless specified otherwise in the command
    debug = true
  }

  # This setting tells cafienne which journal to use for reading events.
  #  If omitted, cafienne will try to guess the read journal, based on the akka settings
  read-journal = "inmemory-read-journal"

  query-db {
    profile = "slick.jdbc.HsqldbProfile$"
    db {
      driver = "org.hsqldb.jdbc.JDBCDriver"
      url = "jdbc:hsqldb:mem:mymemdb"
      # User name to connect, update and query
      user = "SA"
      password = ""
      # User name for migration of schema upon startup
      migrateUser = "SA"
      migratePwd = ""
      numThreads = 10
      connectionTimeout = 5000
      validationTimeout = 5000
    }

    # Configuration options handling exceptions that may occur while reading
    #  the event streams that populate the query-db tables
    #  See also https://doc.akka.io/docs/akka/current/stream/stream-error.html#restart-with-backoff
    restart-stream {
      min-back-off = 500ms
      max-back-off = 30s
      random-factor = 0.20
      max-restarts = 20
    }
  }
}

inmemory-journal {
  event-adapters {
    tagging = "org.cafienne.actormodel.tagging.CaseTaggingEventAdapter"
  }

  event-adapter-bindings {
    "org.cafienne.actormodel.event.ModelEvent" = tagging
  }
}

inmemory-read-journal {
  # Absolute path to the write journal plugin configuration section to get the event adapters from
  write-plugin = "inmemory-journal"

  # ask timeout on Futures
  ask-timeout = "10s"

  # New events are retrieved (polled) with this interval.
  refresh-interval = "100ms"

  # How many events to fetch in one query (replay) and keep buffered until they
  # are delivered downstreams.
  max-buffer-size = "100"
}
